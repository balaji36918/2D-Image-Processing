{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 3",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/balaji36918/2D-Image-Processing/blob/main/Exercise_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_FWw2AID2XU"
      },
      "source": [
        "<h2> Task 1</h2>\n",
        "\n",
        "1. Explain the difference between motion filed and optical flow with example.\n",
        "\n",
        "\n",
        "\n",
        "> While the motion field is the projection from 3D into the 2D picture, the optical flow is bascially the chance of the brightness inside a picture. The change in brightness can be a motion, but the problem is that even a non moving object can look changed while only the origin or number of the light sources was changed. By this the optical flow would show a change while there was no actual movement.\n",
        "\n",
        "\n",
        "> A typical example for this case is the sign in front of a barber shop. While the actual motion is in the horizontal, it looks if we only look on the brightness that the movement is actually taking a vertical way. Therefore it would be the case that the motion field would be showing a change in the horizontal way, while the optical flow would suggest a move in the vertical way.\n",
        "\n",
        "\n",
        "\n",
        "--- \n",
        "<br>\n",
        "\n",
        "2. Explain if the optical flow can be used for tracking bubbles in a glass of carbonated water. Discuss it with respect to the three assumptions of optical flow tracking.\n",
        "\n",
        "\n",
        "\n",
        "> Let us take a look at water bubbles inside the glass in this video:<br> [Carbonated water bubbles in side glass](https://www.youtube.com/watch?v=7ZY9ZyMsizo&t=586s)\n",
        "<br>Now let us come to our 3 assumptions for tracking optical flow.\n",
        "<br> <b>1. Brightness Consistency-</b> We can observe that the brightness of the bubbles is consistent, implying that the projection of the same spot appears the same in each frame. So, the first assumption is satisfied.\n",
        "<br> <b>2. Spatial Coherence-</b> For small patch, one specific pixel in the bubble that we want to track and surrounding pixels have the same motion. Hence the second assumption is satisfied.\n",
        "<br> <b>3. Temporal Persistence-</b> This assumption states that there shall not be abrupt motion of camera or the object we want to track, rather it shall be gradually updated over time. This is where the optical flow tracking gets tricky because few bubbles move rapidly and change their position very quickly between two frames. Hence this third assumption gets violated for few bubbles but for some bubbles it is satisfied.\n",
        "<br> <b>Conclusion-</b> From this we can conclude that optical flow for tracking the bubbles in a glass of carbonated water as all assumptions are satisfied with exception that it might be difficult to track fast moving bubbles.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "3. Explain the aperture problem in optical flow. How can one solve this problem by estimating the global geometric structure of the scene?\n",
        "\n",
        "\n",
        "\n",
        "> <br> The aperture problem refers to the fact that the motion of a one-dimensional spatial structure, such as a bar or edge, cannot be determined unambiguously if it is viewed through a small aperture such that the ends of the stimulus are not visible.\n",
        "<br>Due to aperture problms, similar frames are identified as non similar frames and vice versa.\n",
        "\n",
        "\n",
        "\n",
        "> The following 2 things are done  to solve the aperture problem through Horn Schunck method to compute optical flow:<br>1) Increasing brightness constancy.<br>\n",
        "2) Enforcing smooth flow field .\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "4. The proposed Lucas-Kanade method has an issue with large movement. Why? How can you deal with large movement in the image?\n",
        "\n",
        "\n",
        "\n",
        "> Proposed Lucas-Kanade method has issues with larger movement due to window size. Small window size might miss larger movements and larger window size might be slower. <br>Larger movements can be dealt with coarse to fine registration with iterative refinement.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "<h2>Task 2</h2>\n",
        "\n",
        "Analysis of Result:\n",
        "\n",
        "> The optical flow can be seen as the distribution of apparent velocities of movement of brightness pattern in an image. <br>The flow fields may be used to analyze produce segmentations into regionsthat are associated with moving objects.<br>If we increase the window size in lucas cande parameters, then number of points that we want to detect increases.\n",
        "If we increase the quality level in ShiTomasi corner detection number of points to be detected decreases.<br>For subsequent runs, equal number of points are not detected as well as same points are not detected, so the results are inconsistent.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWe13xZ-Vapr"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33qtxPAMVY4a"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "MCvuoW1jxDwS",
        "outputId": "5ce43780-17ac-419f-fc5e-b4dd1365652c"
      },
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "\n",
        "cap = cv.VideoCapture(0)\n",
        "# params for ShiTomasi corner detection\n",
        "feature_params = dict( maxCorners = 100,\n",
        "                       qualityLevel = 0.3,\n",
        "                       minDistance = 7,\n",
        "                       blockSize = 7 )\n",
        "# Parameters for lucas kanade optical flow\n",
        "lk_params = dict( winSize  = (15,15),\n",
        "                  maxLevel = 2,\n",
        "                  criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03))\n",
        "# Create some random colors\n",
        "color = np.random.randint(0,255,(100,3))\n",
        "# Take first frame and find corners in it\n",
        "ret, old_frame = cap.read()\n",
        "old_gray = cv.cvtColor(old_frame, cv.COLOR_BGR2GRAY)\n",
        "p0 = cv.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
        "# Create a mask image for drawing purposes\n",
        "mask = np.zeros_like(old_frame)\n",
        "while(1):\n",
        "    ret,frame = cap.read()\n",
        "    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
        "    # calculate optical flow\n",
        "    p1, st, err = cv.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
        "    # Select good points\n",
        "    if p1 is not None:\n",
        "        good_new = p1[st==1]\n",
        "        good_old = p0[st==1]\n",
        "    # draw the tracks\n",
        "    for i,(new,old) in enumerate(zip(good_new, good_old)):\n",
        "        a,b = new.ravel()\n",
        "        c,d = old.ravel()\n",
        "        mask = cv.line(mask, (int(a),int(b)),(int(c),int(d)), color[i].tolist(), 2)\n",
        "        frame = cv.circle(frame,(int(a),int(b)),5,color[i].tolist(),-1)\n",
        "    img = cv.add(frame,mask)\n",
        "    cv.imshow('frame',img)\n",
        "    k = cv.waitKey(30) & 0xff\n",
        "    if k == 27:\n",
        "        break\n",
        "    # Now update the previous frame and previous points\n",
        "    old_gray = frame_gray.copy()\n",
        "    p0 = good_new.reshape(-1,1,2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-43499ac0623e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Take first frame and find corners in it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mold_gray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mp0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoodFeaturesToTrack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_gray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfeature_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Create a mask image for drawing purposes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    }
  ]
}